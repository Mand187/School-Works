{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HomeWork 4 Juypter Book\n",
    "\n",
    "# Matthew Anderson | 801203905\n",
    "\n",
    "# Github https://github.com/Mand187/Deep-Learning\n",
    "\n",
    "NOTE FOR GRADER : THIS NOTEBOOK REQUIRES MULTIPLE FILES AS OUTLINE IN THE IMPORT LIST, OTHERWISE THIS WILL NOT WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from hw4Data import *\n",
    "from hw4TrainEval import *\n",
    "from text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "In this homework, we focus on sequence-to-sequence modeling. Use the English to French Dataset provided. \n",
    "\n",
    "Developed a GRU-based encoder-decoder architecture for English to French Translation. Train the model on the entire dataset and evaluate it on the entire dataset. Report training loss, validation loss, and validation accuracy. Also, try some qualitative validation as well, asking the network to generate French translations for some English sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.9933696420530373\n",
      "Epoch 10, Loss: 2.7405671973494843\n",
      "Epoch 20, Loss: 1.6947087448077265\n",
      "Epoch 30, Loss: 0.9132378184200687\n",
      "Epoch 40, Loss: 0.2959807136984763\n",
      "Input: We work in the office, Target: Nous travaillons au bureau, Predicted: Nous travaillons au bureau\n",
      "Input: He waits for the bus, Target: Il attend le bus, Predicted: Il attend le bus\n",
      "Input: They play soccer every weekend, Target: Ils jouent au football chaque week-end, Predicted: Ils jouent au football chaque week-end\n",
      "Input: We build a sandcastle, Target: Nous construisons un château de sable, Predicted: Nous construisons un château de sable\n",
      "Input: The book is on the table, Target: Le livre est sur la table, Predicted: Le livre est sur la table\n",
      "Input: He climbs the mountain, Target: Il gravit la montagne, Predicted: Il gravit la montagne\n",
      "Input: They are students, Target: Ils sont étudiants, Predicted: Ils sont étudiants\n",
      "Input: She runs in the park, Target: Elle court dans le parc, Predicted: Elle court dans le parc\n",
      "Input: He sings beautifully, Target: Il chante magnifiquement, Predicted: Il chante magnifiquement\n",
      "Input: She is happy, Target: Elle est heureuse, Predicted: Elle est heureuse\n",
      "Evaluation Loss: 0.0967725150343979, Accuracy: 0.987012987012987\n"
     ]
    }
   ],
   "source": [
    "word_to_index, index_to_word = create_vocab_mappings(english_to_french, SOS_token, EOS_token)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "n_epochs = 50\n",
    "learning_rate = 0.0085\n",
    "\n",
    "translation_dataset = TranslationDataset(english_to_french, word_to_index)\n",
    "dataloader = DataLoader(translation_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "input_size = len(word_to_index)\n",
    "hidden_size = 256  # Adjust according to your preference\n",
    "output_size = len(word_to_index)\n",
    "\n",
    "encoder = Encoder(input_size=input_size, hidden_size=hidden_size).to(device)\n",
    "decoder = Decoder(hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(encoder, decoder, dataloader, criterion, n_epochs, encoder_optimizer, decoder_optimizer, device)\n",
    "evaluate_and_show_examples(index_to_word, encoder, decoder, dataloader, criterion, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "Repeat problem 1, this time extend the network with attention. Train the model on the entire dataset and evaluate it on the entire dataset. Report training loss, validation loss, and validation accuracy. Also, try some qualitative validation as well, asking the network to generate French translations for some English sentences. Also, compare the results against problem 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.9415355538171832\n",
      "Epoch 10, Loss: 2.6859226175839814\n",
      "Epoch 20, Loss: 1.7407783947195428\n",
      "Epoch 30, Loss: 0.6784322148885858\n",
      "Epoch 40, Loss: 0.18392326294442005\n",
      "Input: They hike in the forest, Target: Ils font de la randonnée dans la forêt, Predicted: Ils font de la randonnée dans la forêt\n",
      "Input: He sings in the choir, Target: Il chante dans le chœur, Predicted: Il chante dans le chœur\n",
      "Input: The flowers bloom in spring, Target: Les fleurs fleurissent au printemps, Predicted: Les fleurs fleurissent au printemps\n",
      "Input: He enjoys reading books, Target: Il aime lire des livres, Predicted: Il aime lire des livres\n",
      "Input: The wind blows gently, Target: Le vent souffle doucement, Predicted: Le vent souffle doucement\n",
      "Input: We watch movies on Fridays, Target: Nous regardons des films le vendredi, Predicted: Nous regardons des films le vendredi\n",
      "Input: The stars twinkle at night, Target: Les étoiles scintillent la nuit, Predicted: Les étoiles scintillent la nuit\n",
      "Input: The restaurant serves delicious food, Target: Le restaurant sert une délicieuse cuisine, Predicted: Le restaurant sert une délicieuse cuisine\n",
      "Input: They read books at the library, Target: Ils lisent des livres à la bibliothèque, Predicted: Ils lisent des livres à la bibliothèque\n",
      "Input: We dance at the wedding, Target: Nous dansons au mariage, Predicted: Nous dansons au mariage\n",
      "Evaluation Loss: 0.12303294569416727, Accuracy: 0.961038961038961\n"
     ]
    }
   ],
   "source": [
    "word_to_index, index_to_word = create_vocab_mappings(french_to_english, SOS_token, EOS_token)\n",
    "\n",
    "input_size = len(word_to_index)\n",
    "hidden_size = 256  # Adjust according to your preference\n",
    "output_size = len(word_to_index)\n",
    "\n",
    "encoder = Encoder(input_size=input_size, hidden_size=hidden_size).to(device)\n",
    "decoder = AttentionDecoder(hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(encoder, decoder, dataloader, criterion, n_epochs, encoder_optimizer, decoder_optimizer, device)\n",
    "evaluate_and_show_examples(index_to_word, encoder, decoder, dataloader, criterion, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "Repeat problems 1 and 2, this time try to translate from French to English. Train the model on the entire dataset and evaluate it on the entire dataset. Report training loss, validation loss, and validation accuracy. Also, try some qualitative validation as well, asking the network to generate English  translations for some French sentences. Which one seems to be more effective, French-to-English or English-to-French?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.986257620148746\n",
      "Epoch 10, Loss: 2.611276131653339\n",
      "Epoch 20, Loss: 1.8652552297645641\n",
      "Epoch 30, Loss: 0.9915714652347608\n",
      "Epoch 40, Loss: 0.31429717740129626\n",
      "Input: The rain falls gently, Target: La pluie tombe doucement, Predicted: La pluie tombe doucement\n",
      "Input: We learn something new every day, Target: Nous apprenons quelque chose de nouveau chaque jour, Predicted: Nous apprenons quelque chose de nouveau chaque jour\n",
      "Input: She walks along the beach, Target: Elle se promène le long de la plage, Predicted: Elle se promène le long de la plage\n",
      "Input: They visit the Eiffel Tower, Target: Ils visitent la tour Eiffel, Predicted: Ils visitent la tour Eiffel\n",
      "Input: He waits for the bus, Target: Il attend le bus, Predicted: Il attend le bus\n",
      "Input: I am cold, Target: J'ai froid, Predicted: J'ai froid\n",
      "Input: The stars twinkle at night, Target: Les étoiles scintillent la nuit, Predicted: Les étoiles scintillent la nuit\n",
      "Input: They hike in the forest, Target: Ils font de la randonnée dans la forêt, Predicted: Ils font de la randonnée dans la forêt\n",
      "Input: We play music at the concert, Target: Nous jouons de la musique au concert, Predicted: Nous jouons de la musique au concert\n",
      "Input: We watch a movie together, Target: Nous regardons un film ensemble, Predicted: Nous regardons un film ensemble\n",
      "Evaluation Loss: 0.10699702522569011, Accuracy: 0.974025974025974\n"
     ]
    }
   ],
   "source": [
    "word_to_index, index_to_word = create_vocab_mappings(french_to_english, SOS_token, EOS_token)\n",
    "\n",
    "input_size = len(word_to_index)\n",
    "hidden_size = 256  # Adjust according to your preference\n",
    "output_size = len(word_to_index)\n",
    "\n",
    "encoder = Encoder(input_size=input_size, hidden_size=hidden_size).to(device)\n",
    "decoder = Decoder(hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(encoder, decoder, dataloader, criterion, n_epochs, encoder_optimizer, decoder_optimizer, device)\n",
    "evaluate_and_show_examples(index_to_word, encoder, decoder, dataloader, criterion, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3 Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 4.11143126309815\n",
      "Epoch 10, Loss: 2.656912607651252\n",
      "Epoch 20, Loss: 1.7228302225528909\n",
      "Epoch 30, Loss: 0.8809720610680227\n",
      "Epoch 40, Loss: 0.24682250702763264\n",
      "Input: Le chat miaule bruyamment, Target: The cat meows loudly, Predicted: The cat meows loudly\n",
      "Input: Il chante magnifiquement, Target: He sings beautifully, Predicted: He sings beautifully\n",
      "Input: Tu es fatigué, Target: You are tired, Predicted: You are tired\n",
      "Input: sont es étudiants, Target: They students Ils, Predicted: They students Ils\n",
      "Input: est promène long autour plage, Target: She sets walks dinner along to music beach, Predicted: She sets walks dinner along to music beach\n",
      "Input: est chante is chanson, Target: She sings red song, Predicted: She sings red song\n",
      "Input: sommes petit déjeuner ensemble, Target: We eat dinner breakfast prenons cuisinons, Predicted: We eat dinner breakfast prenons cuisinons\n",
      "Input: Le pluie tombe doucement, Target: rain falls gently La, Predicted: rain falls gently La\n",
      "Input: Il en faisant musique du de, Target: He listens to music aimons while jogging écoute de, Predicted: He listens to music aimons while jogging écoute the\n",
      "Input: Il les l'histoire, Target: He studies history, Predicted: He studies history\n",
      "Evaluation Loss: 0.10020538087687744, Accuracy: 0.974025974025974\n"
     ]
    }
   ],
   "source": [
    "word_to_index, index_to_word = create_vocab_mappings(english_to_french, SOS_token, EOS_token)\n",
    "\n",
    "input_size = len(word_to_index)\n",
    "hidden_size = 256  # Adjust according to your preference\n",
    "output_size = len(word_to_index)\n",
    "\n",
    "encoder = Encoder(input_size=input_size, hidden_size=hidden_size).to(device)\n",
    "decoder = Decoder(hidden_size=hidden_size, output_size=output_size).to(device)\n",
    "\n",
    "encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "train_model(encoder, decoder, dataloader, criterion, n_epochs, encoder_optimizer, decoder_optimizer, device)\n",
    "evaluate_and_show_examples(index_to_word, encoder, decoder, dataloader, criterion, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
